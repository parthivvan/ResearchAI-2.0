from flask import Flask, request, jsonify
from flask_cors import CORS
import os
from transformers import T5Tokenizer, T5ForConditionalGeneration
from PyPDF2 import PdfReader
from werkzeug.utils import secure_filename
import uuid
import docx
import logging
from chromadb import PersistentClient
from datetime import datetime
from pymongo import MongoClient
import re

app = Flask(__name__)
CORS(app)

UPLOAD_FOLDER = 'uploads'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 10 * 1024 * 1024  # 10MB max

# ChromaDB setup
chroma_client = PersistentClient(path="./chroma_db")
collection = chroma_client.get_or_create_collection(name="research_papers")

# MongoDB setup
mongo_client = MongoClient('mongodb://localhost:27017/')
db = mongo_client['researchai']
history_collection = db['History']

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load FLAN-T5
logger.info("Loading FLAN-T5...")
tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-base")
model = T5ForConditionalGeneration.from_pretrained("google/flan-t5-base")
logger.info("FLAN-T5 loaded.")

# ---------- TEXT EXTRACTION ----------
def extract_text_from_pdf(file_path):
    try:
        text = ""
        with open(file_path, "rb") as file:
            reader = PdfReader(file)
            for i, page in enumerate(reader.pages):
                text += (page.extract_text() or "") + "\n"
                if i > 50:
                    break
        return text.strip()
    except Exception as e:
        logger.error(f"PDF error: {str(e)}")
        return None

def extract_text_from_docx(file_path):
    try:
        doc = docx.Document(file_path)
        return "\n".join(para.text for para in doc.paragraphs if para.text.strip())
    except Exception as e:
        logger.error(f"DOCX error: {str(e)}")
        return None

def extract_text_from_txt(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            return file.read(500000).strip()
    except Exception as e:
        logger.error(f"TXT error: {str(e)}")
        return None

def clean_text(text):
    text = re.sub(r'http\S+|www\S+|https\S+', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text[:100000]

# ---------- ENDPOINT: /summarize ----------
@app.route('/summarize', methods=['POST'])
def summarize():
    try:
        if 'file' not in request.files:
            return jsonify({"error": "No file uploaded"}), 400
        file = request.files['file']
        if file.filename == '':
            return jsonify({"error": "Empty filename"}), 400

        file.seek(0, 2)
        file_size = file.tell()
        file.seek(0)
        if file_size > app.config['MAX_CONTENT_LENGTH']:
            return jsonify({"error": "File too large"}), 400

        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)

        ext = filename.lower().split('.')[-1]
        text = None
        if ext == 'pdf':
            text = extract_text_from_pdf(filepath)
        elif ext == 'docx':
            text = extract_text_from_docx(filepath)
        elif ext == 'txt':
            text = extract_text_from_txt(filepath)
        else:
            return jsonify({"error": "Unsupported file format"}), 400

        if not text:
            return jsonify({"error": "Text extraction failed"}), 500

        text = clean_text(text)
        doc_id = str(uuid.uuid4())
        collection.add(
            ids=[doc_id],
            documents=[text],
            metadatas=[{"source": filename}]
        )

        history_collection.insert_one({
            "doc_id": doc_id,
            "filename": filename,
            "timestamp": datetime.utcnow(),
            "status": "uploaded",
            "user_id": request.remote_addr,
            "text_preview": text[:200] + "..." if len(text) > 200 else text
        })

        return jsonify({
            "message": "File uploaded successfully",
            "doc_id": doc_id,
            "source": filename,
            "text_preview": text[:200] + "..." if len(text) > 200 else text
        })

    except Exception as e:
        logger.error(f"/summarize error: {str(e)}")
        return jsonify({"error": str(e)}), 500

# ---------- ENDPOINT: /generate_summary ----------
@app.route('/generate_summary', methods=['POST'])
def generate_summary():
    try:
        data = request.get_json()
        doc_id = data.get('doc_id')

        results = collection.get(ids=[doc_id], include=["documents", "metadatas"])
        if not results['documents']:
            return jsonify({"error": "Document not found"}), 404

        text = results['documents'][0]
        filename = results['metadatas'][0].get('source', 'unknown')

        # Improved summary generation with structured prompt
        summary_prompt = (
            "Write a comprehensive 250-word summary of this research paper covering:\n"
            "1. Background and objectives of the study\n"
            "2. Methodology and data sources used\n"
            "3. Key findings and results\n"
            "4. Significance and implications of the research\n"
            "5. Conclusions and future directions\n\n"
            "Paper content:\n" + text[:6000]
        )
        inputs = tokenizer(
            summary_prompt,
            return_tensors="pt",
            max_length=1024,
            truncation=True
        )
        summary_ids = model.generate(
            inputs.input_ids,
            max_length=512,
            min_length=250,
            num_beams=4,
            no_repeat_ngram_size=3,
            early_stopping=True,
            temperature=0.7
        )
        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)

        # Improved advantages generation with specific focus
        adv_prompt = (
            "List 3-5 specific strengths or valuable contributions of this research. "
            "Focus on:\n"
            "- Novel methodologies or approaches used\n"
            "- Important findings or discoveries\n"
            "- Practical applications or implementations\n"
            "- Theoretical contributions to the field\n"
            "- Any other significant strengths\n\n"
            "Provide concrete examples from this paper:\n" + text[:4000]
        )
        adv_inputs = tokenizer(
            adv_prompt,
            return_tensors="pt",
            max_length=1024,
            truncation=True
        )
        adv_ids = model.generate(
            adv_inputs.input_ids,
            max_length=300,
            num_beams=4,
            no_repeat_ngram_size=3,
            temperature=0.8
        )
        advantages_text = tokenizer.decode(adv_ids[0], skip_special_tokens=True)
        advantages = [line.strip('-*• ').strip() for line in advantages_text.split('\n') if line.strip()]
        advantages = list(dict.fromkeys(advantages))[:5]  # Deduplicate and limit to 5

        # Improved disadvantages generation with different focus
        disadv_prompt = (
            "List 3-5 specific limitations or weaknesses of this research. "
            "Focus on:\n"
            "- Methodological constraints or flaws\n"
            "- Data limitations or sample size issues\n"
            "- Scope or generalizability limitations\n"
            "- Potential biases or confounding factors\n"
            "- Any other significant weaknesses\n\n"
            "Provide concrete examples from this paper:\n" + text[:4000]
        )
        disadv_inputs = tokenizer(
            disadv_prompt,
            return_tensors="pt",
            max_length=1024,
            truncation=True
        )
        disadv_ids = model.generate(
            disadv_inputs.input_ids,
            max_length=300,
            num_beams=4,
            no_repeat_ngram_size=3,
            temperature=0.8
        )
        disadvantages_text = tokenizer.decode(disadv_ids[0], skip_special_tokens=True)
        disadvantages = [line.strip('-*• ').strip() for line in disadvantages_text.split('\n') if line.strip()]
        disadvantages = list(dict.fromkeys(disadvantages))[:5]  # Deduplicate and limit to 5

        # Final quality checks
        summary = '. '.join([s.strip().capitalize() for s in summary.split('.') if s.strip()])
        
        # Ensure advantages and disadvantages are different
        disadvantages = [d for d in disadvantages if not any(d.lower() in a.lower() for a in advantages)]
        advantages = [a for a in advantages if not any(a.lower() in d.lower() for d in disadvantages)]

        # Ensure we have at least 3 items for each
        advantages = advantages[:3] if len(advantages) > 3 else advantages
        disadvantages = disadvantages[:3] if len(disadvantages) > 3 else disadvantages

        history_collection.update_one(
            {"doc_id": doc_id},
            {"$set": {
                "status": "summarized",
                "summary": summary,
                "advantages": advantages,
                "disadvantages": disadvantages,
                "last_updated": datetime.utcnow()
            }}
        )

        return jsonify({
            "summary": summary,
            "advantages": advantages,
            "disadvantages": disadvantages,
            "doc_id": doc_id,
            "source": filename
        })

    except Exception as e:
        logger.error(f"/generate_summary error: {str(e)}")
        return jsonify({"error": str(e)}), 500

# ---------- ENDPOINT: /ask ----------
@app.route('/ask', methods=['POST'])
def ask_question():
    try:
        data = request.get_json()
        question = data.get('question', '').strip()
        doc_id = data.get('doc_id')

        if not question or not doc_id:
            return jsonify({"error": "Missing question or doc_id"}), 400

        results = collection.get(ids=[doc_id], include=["documents"])
        if not results['documents']:
            return jsonify({"error": "Document not found"}), 404

        context = results['documents'][0][:5000]

        inputs = tokenizer(
            f"Answer this based on the paper:\nQuestion: {question}\nContext: {context}",
            return_tensors="pt",
            max_length=1024,
            truncation=True
        )
        answer_ids = model.generate(inputs.input_ids, max_length=200, num_beams=4)
        answer = tokenizer.decode(answer_ids[0], skip_special_tokens=True)

        history_collection.update_one(
            {"doc_id": doc_id},
            {"$push": {"interactions": {
                "question": question,
                "answer": answer,
                "timestamp": datetime.utcnow()
            }}}
        )

        return jsonify({"answer": answer, "context_used": len(context)})
    except Exception as e:
        logger.error(f"/ask error: {str(e)}")
        return jsonify({"error": str(e)}), 500

# ---------- ENDPOINT: /history ----------
@app.route('/history', methods=['GET'])
def get_history():
    try:
        user_id = request.args.get('user_id', request.remote_addr)
        history = list(history_collection.find(
            {"user_id": user_id},
            {"_id": 0, "doc_id": 1, "filename": 1, "timestamp": 1, "status": 1, "summary": 1}
        ).sort("timestamp", -1).limit(10))

        for item in history:
            item['upload_date'] = item.pop('timestamp').isoformat()

        return jsonify(history)
    except Exception as e:
        logger.error(f"/history error: {str(e)}")
        return jsonify({"error": str(e)}), 500

# ---------- ENDPOINT: /document/<doc_id> ----------
@app.route('/document/<doc_id>', methods=['GET'])
def get_document_details(doc_id):
    try:
        history_item = history_collection.find_one({"doc_id": doc_id}, {"_id": 0})
        if history_item:
            results = collection.get(ids=[doc_id], include=["documents", "metadatas"])
            full_text = results['documents'][0] if results['documents'] else None
            history_item['full_text'] = full_text
            return jsonify(history_item)
        return jsonify({"error": "Document not found"}), 404
    except Exception as e:
        logger.error(f"/document error: {str(e)}")
        return jsonify({"error": str(e)}), 500

# ---------- HEALTH CHECK ----------
@app.route('/')
def health_check():
    return jsonify({
        "status": "running",
        "endpoints": {
            "/summarize": "POST - Upload document",
            "/generate_summary": "POST - Generate summary",
            "/ask": "POST - Ask questions",
            "/history": "GET - Get document history",
            "/document/<doc_id>": "GET - Document details"
        }
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, threaded=True)
